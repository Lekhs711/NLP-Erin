{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 6 - Executive Session 2\n",
    "\n",
    "This project is inspired by Julia Silge's work on text mining in different areas. Check out the blogs below to see what you might consider doing:\n",
    "\n",
    "- https://juliasilge.com/blog/gender-pronouns/\n",
    "- https://pudding.cool/2017/08/screen-direction/\n",
    "\n",
    "For this assignment pick TWO words that you are interested in comparing with each other. You will compare either the n-gram before them (i.e., the few words before your target word) or the n-gram behind them (i.e., the few words after your target word). I'd recommend nouns or adjectives that would be present in your chosen corpus. \n",
    "\n",
    "## Enter your two words here: Not, Great  \n",
    "\n",
    "## What do you think the differences will be in those two words?\n",
    "Great is a positive word and Not is a negative word. This could be used as a sarcastic word "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import a dataset\n",
    "\n",
    "Chapter 3 - Find a dataset that you think is appropriate to test your hypothesis. You can use longer text works from Project Gutenberg, webpages, downloadable corpora, etc. It should not be a corpus used in `nltk`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"@AmericanAir why would I even consider continuing your point program when I received no perks or continued bad customer service? #senseless\\n@AmericanAir we've already made other arrangements ourselves.\\n@AmericanAir thanks for getting back to me. But I will find other airlines in the future.\\n@AmericanAir why would I pay $200 to reactivate my points that are only useful for certain flights that aren't even worth $200?\\n@AmericanAir stranded for 24 hours in MIA, Patrick casimir has been the ONLY AA staff to apologize for the great inconvenience #unreal\\n@AmericanAir no thanks.  As I said, being denied miles that expired one week ago was the last drop for me; plan to avoid AA as possible.\\n@AmericanAir sorry so Late Flight, responded to your DM.\\n@AmericanAir Believe me, I understand. Flight #2955. Was originally booked for Sunday. Flight was Cancelled Flighted and rescheduled for today.\\n@AmericanAir aa employees were rude and unwilling to help. 10,000 miles is a rotten cherry on top of a dog shit Sunday. #nocareforcustomers\\n@AmericanAir Mold on my flight?!? US3825 #filthyplane #hopeidonotgetsick http://t.co/zIK2UoXGnW\\n@AmericanAir 767 seconds from touchdown at Madrid airport in April 2013 #AvGeek http://t.co/1yWXRfn0Gr\\n@AmericanAir I slept in the miami airport due to mechanical issues and was given 10,000 bonus miles to try and make it right. #slapintheface\\n@AmericanAir is the new 9:45 time confirmed or it may get Cancelled Flightled? Traveling with kids, need to be certain. Thx\\n@AmericanAir 1hr 46 min. Cost of flight change $788. Was $188 2hrs ago b/f drop call. Cancelled Flighted flight. Asked 4 refund.\\n@AmericanAir it's not just frustrating--it was PAID for! how do we get a refund?\\n@AmericanAir DM the locator code, thanks.\\n@AmericanAir thank you!\\n@AmericanAir I sure hope you all can fix @USAirways. Good luck, their service sucks. #nexttimeiwillflysouthwest\\n@americanair thanks for no fresh food on my cross country flight and for making my connection so close No time to e\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('American Airlines.txt', 'r') as data:\n",
    "    twitter_data = data.read()\n",
    "    \n",
    "twitter_data[:2000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up the dataset\n",
    "\n",
    "Chapter 3 - Clean the dataset so it only contains the information you are looking for. If you use books, cut off the extra stuff at the beginning or end. If you use HTML, be sure to process it with `beautifulsoup`. \n",
    "\n",
    "Chapter 2 and on - Put everything in the corpus into lower case. \n",
    "\n",
    "Chapter 3 - Tokenize the dataset into words and sentences (two separate variables, you will use them both). Consider naming things `raw` for the complete character string, `words` for the tokenized words, and `sents` for the sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" Chef &amp; the beauty of San Miguel de Allende. My Late Flightst food blog.  http://t.co/7t1rDRCRe6\\nGreat, thanks. Followed.\\nThis is exactly why ill be flying AA from to Dallas! Only airline I trust!\\nThis doesn't address my issue. I am on hold for 30 min to speak with an agent.\\ngot another flight. Thanks you\\nu r horrible.went online to Cancelled Flight flight-no button-4that.Called CS &amp;wait time 40 mins&amp;put in my #.800#called&amp;it hungupNOHELP\\nsubmitted a case to AA customer relations two weeks ago, no word ever since! whats the point of even having CR?\\nif by near the gate you mean sitting on the plane for almost 2 hours, then yeah.\\nI don't think you should help him at all based on his behavior. The voucher and cot seem like enough lol üòÉ\\nstill waiting for a flight... I should get my money back\\nI Cancelled Flighted my flight. I really don‚Äôt need this much trouble.\\n‚Äú@AmericanAir: We're sorry you were uncomfortable, Andrew. What can we do for you?‚Äù SMA\\nHi, can you please ticket\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#removing the fitered text \n",
    "import re\n",
    "del_text = re.sub(r'[@][\\w]*[\\s]', '', twitter_data)\n",
    "del_text[3000:4000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'food blog.  \\nGreat, thanks. Followed.\\nThis is exactly why ill be flying AA from to Dallas! Only airline I trust!\\nThis doesn\\'t address my issue. I am on hold for 30 min to speak with an agent.\\ngot another flight. Thanks you\\nu r horrible.went online to Cancelled Flight flight-no button-4that.Called CS &amp;wait time 40 mins&amp;put in my #.800#called&amp;it hungupNOHELP\\nsubmitted a case to AA customer relations two weeks ago, no word ever since! whats the point of even having CR?\\nif by near the gate you mean sitting on the plane for almost 2 hours, then yeah.\\nI don\\'t think you should help him at all based on his behavior. The voucher and cot seem like enough lol üòÉ\\nstill waiting for a flight... I should get my money back\\nI Cancelled Flighted my flight. I really don‚Äôt need this much trouble.\\n‚Äú@AmericanAir: We\\'re sorry you were uncomfortable, Andrew. What can we do for you?‚Äù SMA\\nHi, can you please ticket my award ticket? The status is \"On Request\" now. Thanks.\\ngot back eventually! Was a rol'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#removing https\n",
    "del_http = re.sub(r'http\\S+', '', del_text)\n",
    "del_http[3000:4000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'food blog.  \\nGreat, thanks. Followed.\\nThis is exactly why ill be flying AA from to Dallas! Only airline I trust!\\nThis doesn\\'t address my issue. I am on hold for 30 min to speak with an agent.\\ngot another flight. Thanks you\\nu r horrible.went online to Cancelled Flight flight-no button-4that.Called CS &amp;wait time 40 mins&amp;put in my #.800#called&amp;it hungupNOHELP\\nsubmitted a case to AA customer relations two weeks ago, no word ever since! whats the point of even having CR?\\nif by near the gate you mean sitting on the plane for almost 2 hours, then yeah.\\nI don\\'t think you should help him at all based on his behavior. The voucher and cot seem like enough lol \\nstill waiting for a flight... I should get my money back\\nI Cancelled Flighted my flight. I really don‚Äôt need this much trouble.\\n‚Äú@AmericanAir: We\\'re sorry you were uncomfortable, Andrew. What can we do for you?‚Äù SMA\\nHi, can you please ticket my award ticket? The status is \"On Request\" now. Thanks.\\ngot back eventually! Was a roll'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RE_EMOJI = re.compile(\"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "def strip_emoji(string):\n",
    "    return RE_EMOJI.sub(r'', string)\n",
    "\n",
    "del_emojis = strip_emoji(del_http)\n",
    "del_emojis[3000:4000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'wed.This is exactly why ill be flying AA from to Dallas! Only airline I trust!This doesn\\'t address my issue. I am on hold for 30 min to speak with an agent.got another flight. Thanks youu r horrible.went online to Cancelled Flight flight-no button-4that.Called CS &amp;wait time 40 mins&amp;put in my #.800#called&amp;it hungupNOHELPsubmitted a case to AA customer relations two weeks ago, no word ever since! whats the point of even having CR?if by near the gate you mean sitting on the plane for almost 2 hours, then yeah.I don\\'t think you should help him at all based on his behavior. The voucher and cot seem like enough lol still waiting for a flight... I should get my money backI Cancelled Flighted my flight. I really don‚Äôt need this much trouble.‚Äú@AmericanAir: We\\'re sorry you were uncomfortable, Andrew. What can we do for you?‚Äù SMAHi, can you please ticket my award ticket? The status is \"On Request\" now. Thanks.got back eventually! Was a rollercoaster. Once I got to the airport &amp; go'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#remove new lines\n",
    "def remove_newlines(string):\n",
    "    return re.sub(r'\\n','',string)\n",
    "\n",
    "del_nl = remove_newlines(del_emojis)\n",
    "del_nl[3000:4000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = del_nl.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['traveling', 'with', 'kids', ',', 'need', 'to', 'be', 'certain', '.']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "words = nltk.word_tokenize(raw)\n",
    "sents = nltk.sent_tokenize(raw)\n",
    "sents = [nltk.word_tokenize(sent) for sent in sents]\n",
    "sents[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create A Tagger\n",
    "\n",
    "Use the following site to see the available corpora in `nltk`: http://www.nltk.org/nltk_data/. Pick the one that best matches your target dataset, and you will need to make sure it includes tagged sentences. You make need to use the download function from Chapter 1 to be able to import that corpus. \n",
    "\n",
    "Chapter 5 - Train a tagger on 90% of the data.\n",
    "\n",
    "Test the tagger on 10% of the data. \n",
    "\n",
    "## How well did your tagger do? \n",
    "<br>\n",
    "The tagger used below is doing a pretty good job as to out of 100, 82 are correctly tagged\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('Debate', 'NN'), ('Transcript', 'NNP'), ('October', 'NNP'), ('11', 'CD'), (',', ','), ('2000', 'CD'), ('The', 'DT'), ('Second', 'NNP'), ('Gore-', 'NNP'), ('Bush', 'NNP'), ('Presidential', 'NNP'), ('Debate', 'NN'), ('Let', 'VB'), (\"'s\", 'PRP'), ('welcome', 'VB'), ('the', 'DT'), ('candidates', 'NNS'), (',', ','), ('Governor', 'NNP'), ('Bush', 'NNP'), ('and', 'CC'), ('Vice', 'NNP'), ('President', 'NNP'), ('Gore', 'NNP'), ('.', '.')], [('Good', 'JJ'), ('evening', 'NN'), (',', ','), ('from', 'IN'), ('Wake', 'NNP'), ('Chapel', 'NNP'), ('at', 'IN'), ('Wake', 'NNP'), ('Forest', 'NNP'), ('University', 'NNP'), ('at', 'IN'), ('Winston-', 'NNP'), ('Salem', 'NNP'), (',', ','), ('North', 'NNP'), ('Carolina', 'NNP'), ('.', '.')], ...]\n"
     ]
    }
   ],
   "source": [
    "#let us use the masc tagged word corpus and train the data \n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import masc_tagged\n",
    "\n",
    "masc_tagged_tagged_sents = masc_tagged.tagged_sents()\n",
    "print(masc_tagged_tagged_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = int(len(masc_tagged_tagged_sents) * 0.9)\n",
    "##break apart the data based on that split\n",
    "train_sents = masc_tagged_tagged_sents[:size]\n",
    "test_sents = masc_tagged_tagged_sents[size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8216609890755315"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##create a function (traiing) on the first part\n",
    "unigram_tagger = nltk.UnigramTagger(train_sents)\n",
    "##test on the second part\n",
    "unigram_tagger.evaluate(test_sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tag Your Data\n",
    "\n",
    "Chapter 5 - Use your trained tagger to tag the target corpus. \n",
    "\n",
    "Pick a random sentence and print it out.\n",
    "\n",
    "## How well do you think the sentence is tagged?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('flight', 'NN'),\n",
       " ('was', 'VBD'),\n",
       " ('cancelled', 'JJ'),\n",
       " ('flighted', None),\n",
       " ('and', 'CC'),\n",
       " ('rescheduled', None),\n",
       " ('for', 'IN'),\n",
       " ('today.aa', None),\n",
       " ('employees', 'NNS'),\n",
       " ('were', 'VBD'),\n",
       " ('rude', 'JJ'),\n",
       " ('and', 'CC'),\n",
       " ('unwilling', None),\n",
       " ('to', 'TO'),\n",
       " ('help', 'VB'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged_sents = unigram_tagger.tag_sents(sents)\n",
    "tagged_sents[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('why', 'WRB'),\n",
       " ('would', 'MD'),\n",
       " ('i', 'NNP'),\n",
       " ('even', 'RB'),\n",
       " ('consider', 'VB'),\n",
       " ('continuing', 'VBG'),\n",
       " ('your', 'PRP$'),\n",
       " ('point', 'NN'),\n",
       " ('program', 'NN'),\n",
       " ('when', 'WRB'),\n",
       " ('i', 'NNP'),\n",
       " ('received', 'VBD'),\n",
       " ('no', 'DT'),\n",
       " ('perks', None),\n",
       " ('or', 'CC'),\n",
       " ('continued', 'VBD'),\n",
       " ('bad', 'JJ'),\n",
       " ('customer', 'NN'),\n",
       " ('service', 'NN'),\n",
       " ('?', '.')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged_words = unigram_tagger.tag (words)\n",
    "tagged_words[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chapter 5 - Create a frequency distribution of the parts of speech from your tagged corpus. \n",
    "\n",
    "Print out the list in descending order (most frequent to least frequent).\n",
    "\n",
    "## Does the list match what you would expect given our previous examples? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('NN', 6973),\n",
       " (None, 6046),\n",
       " ('IN', 4832),\n",
       " ('.', 3707),\n",
       " ('DT', 3167),\n",
       " ('VB', 2703),\n",
       " ('RB', 2695),\n",
       " ('PRP', 2326),\n",
       " ('JJ', 2317),\n",
       " ('VBP', 1769),\n",
       " ('TO', 1736),\n",
       " ('NNS', 1696),\n",
       " ('VBD', 1377),\n",
       " ('CC', 1320),\n",
       " ('VBZ', 1224),\n",
       " ('NNP', 1174),\n",
       " ('PRP$', 1159),\n",
       " ('VBG', 1047),\n",
       " ('VBN', 988),\n",
       " (',', 916),\n",
       " ('MD', 897),\n",
       " ('CD', 892),\n",
       " ('#', 534),\n",
       " (':', 381),\n",
       " ('WRB', 361),\n",
       " ('...', 222),\n",
       " ('RP', 211),\n",
       " ('WP', 180),\n",
       " ('JJR', 141),\n",
       " ('EX', 112),\n",
       " (')', 106),\n",
       " ('(', 87),\n",
       " ('JJS', 85),\n",
       " ('$', 64),\n",
       " ('UH', 48),\n",
       " ('WDT', 24),\n",
       " ('RBR', 20),\n",
       " ('FW', 16),\n",
       " ('SYM', 13),\n",
       " ('RBS', 9),\n",
       " ('POS', 8),\n",
       " ('LS', 6),\n",
       " ('WP$', 4)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_fd = nltk.FreqDist(tag for (word, tag) in tagged_words) \n",
    "tag_fd.most_common()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes, the list matches the expection from previous examples. NN is the highest. There are also lot of None which is due to mismatch in the type of data set. A better dataset for training UnigramTagger will result in less None."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore your words\n",
    "\n",
    "Chapter 1 - Use the `similar` function to similar words to your two words. Remember the some of the `nltk` functions require that your input be a specific nltkText type. \n",
    "\n",
    "## Interpret your findings - are these words similar? What do the results appear to tell you?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you i is it was to there that now the been already in flight on this\n",
      "could ca never when\n"
     ]
    }
   ],
   "source": [
    "# Lets create a nltkText type\n",
    "text1 = nltk.Text(words)\n",
    "text1.similar('not')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "your customer happy worst horrible why when no for booked a not how\n",
      "sure all their able what glad phone\n"
     ]
    }
   ],
   "source": [
    "text1.similar('great')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No these words are not similar. Not has been used with nouns like flight, could etc.  Where as great is used with negation words like horrible, worst where as it was supposed to be the opposite."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chapter 1 - Use the `common_contexts` function to display the contexts for each of your words.\n",
    "\n",
    "## Interpret your findings - are the contexts similar? What contexts do the words appear in?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is_i\n"
     ]
    }
   ],
   "source": [
    "text1.common_contexts(['not','great'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chapter 1 - Create a dispersion plot of your two words in the text.\n",
    "\n",
    "## Do they appear to be used evenly across the text?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1151a8828>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "text1.dispersion_plot([\"not\", \"great\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chapter 1 - Use the `count` function to count the number of times each word has appeared in the text.\n",
    "\n",
    "## Are the counts equal or is one used more frequently than the other?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "354"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1.count('not')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1.count('great')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No, the counts are not equal. \"not\" is used more frequently than \"great\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chapter 2 - Using WordNet calculate the semantic similarity between your two words with `path_similarity`.\n",
    "\n",
    "## How related do these two words appear to be?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('great.n.01'),\n",
       " Synset('great.s.01'),\n",
       " Synset('great.s.02'),\n",
       " Synset('great.s.03'),\n",
       " Synset('bang-up.s.01'),\n",
       " Synset('capital.s.03'),\n",
       " Synset('big.s.13')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "wn.synsets('great')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('not.r.01')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synsets('not')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "great_wn = wn.synset('great.n.01')\n",
    "not_wn = wn.synset('not.r.01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(great_wn.path_similarity(not_wn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because this came out to be None, lets change the word to something like \"customer\" as customer was seen near \"great\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('customer.n.01')]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synsets('customer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16666666666666666\n"
     ]
    }
   ],
   "source": [
    "customer_wn = wn.synset('customer.n.01')\n",
    "print(great_wn.path_similarity(customer_wn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no relation between the 'not' and 'great'. There is very less relation between 'great' and 'customer' which shows that the twitter data for America airlines reviews have very less combination of words \"great customer\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chapter 3 - What are the commonly paired words with your words? There are lots of ways to get at these, but consider regular expressions to give you the most flexibility with your search. \n",
    "\n",
    "For this question, make a frequency distribution of the words that you see most commonly around your two target words (do each word separately). Then print out the most common occurrences for each word in descending order.\n",
    "\n",
    "## Interpret your findings here. For each word, what are the most common words associated with it? Do these overlap? What do they imply about the actions/actors in the text?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(\"'s\", 30),\n",
       " ('is', 29),\n",
       " ('.', 26),\n",
       " (',', 17),\n",
       " ('can', 17),\n",
       " ('do', 16),\n",
       " ('have', 14),\n",
       " ('and', 13),\n",
       " ('?', 13),\n",
       " ('be', 12)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "not_neighbours = []\n",
    "for i,el in enumerate(words):\n",
    "    if (el == 'not'):\n",
    "        not_neighbours.append(words[i-1])\n",
    "        not_neighbours.append(words[i+1])\n",
    "fd = nltk.FreqDist(not_neighbours)\n",
    "fd.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('.', 13),\n",
       " ('a', 6),\n",
       " (',', 5),\n",
       " ('customer', 5),\n",
       " ('the', 4),\n",
       " ('?', 4),\n",
       " ('!', 4),\n",
       " ('be', 4),\n",
       " ('job', 4),\n",
       " ('inconvenience', 2)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "great_neighbours = []\n",
    "for i,el in enumerate(words):\n",
    "    if (el == 'great'):\n",
    "        great_neighbours.append(words[i-1])\n",
    "        great_neighbours.append(words[i+1])\n",
    "fd = nltk.FreqDist(great_neighbours)\n",
    "fd.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('service', 93),\n",
       " ('your', 12),\n",
       " ('relations', 9),\n",
       " ('a', 8),\n",
       " ('.', 7),\n",
       " ('worst', 6),\n",
       " ('poor', 6),\n",
       " ('the', 6),\n",
       " ('no', 5),\n",
       " ('great', 5)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customer_neighbours = []\n",
    "for i,el in enumerate(words):\n",
    "    if (el == 'customer'):\n",
    "        customer_neighbours.append(words[i-1])\n",
    "        customer_neighbours.append(words[i+1])\n",
    "fd = nltk.FreqDist(customer_neighbours)\n",
    "fd.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'not' and 'great' don't seem to overlap much. But 'customer' and 'great' do overlap."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chapter 5 - What are the most common parts of speech with your words? Create a frequency distribution of the part of speech that comes either before or after your words (match what you did above choosing before or after). Print them out in descending order. \n",
    "\n",
    "## Interpret your findings. What are these words doing differently (if at all)? Does one of them have more action while the other has more description?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('VBP', 70),\n",
       " ('VBZ', 69),\n",
       " (None, 57),\n",
       " ('JJ', 55),\n",
       " ('VB', 53),\n",
       " ('.', 47),\n",
       " ('RB', 40),\n",
       " ('MD', 40),\n",
       " ('NN', 40),\n",
       " ('VBG', 38)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "not_neighbours = []\n",
    "not_neighbours_tags = []\n",
    "for i,(el,tag) in enumerate(tagged_words):\n",
    "    if (el == 'not'):\n",
    "        not_neighbours.append(tagged_words[i-1][0])\n",
    "        not_neighbours_tags.append(tagged_words[i-1][1])\n",
    "        not_neighbours.append(tagged_words[i+1][0])\n",
    "        not_neighbours_tags.append(tagged_words[i+1][1])\n",
    "fd = nltk.FreqDist(not_neighbours_tags)\n",
    "fd.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('NN', 23),\n",
       " ('.', 21),\n",
       " ('DT', 11),\n",
       " (',', 5),\n",
       " (None, 5),\n",
       " ('VB', 5),\n",
       " ('NNS', 4),\n",
       " ('VBP', 3),\n",
       " ('VBZ', 2),\n",
       " ('...', 2)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "great_neighbours = []\n",
    "great_neighbours_tags = []\n",
    "for i,(el,tag) in enumerate(tagged_words):\n",
    "    if (el == 'great'):\n",
    "        great_neighbours.append(tagged_words[i-1][0])\n",
    "        great_neighbours_tags.append(tagged_words[i-1][1])\n",
    "        great_neighbours.append(tagged_words[i+1][0])\n",
    "        great_neighbours_tags.append(tagged_words[i+1][1])\n",
    "fd = nltk.FreqDist(great_neighbours_tags)\n",
    "fd.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('NN', 101),\n",
       " (None, 41),\n",
       " ('JJ', 37),\n",
       " ('DT', 24),\n",
       " ('IN', 18),\n",
       " ('PRP$', 16),\n",
       " ('NNS', 13),\n",
       " ('.', 9),\n",
       " ('JJS', 6),\n",
       " ('CD', 4)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customer_neighbours = []\n",
    "customer_neighbours_tags = []\n",
    "for i,(el,tag) in enumerate(tagged_words):\n",
    "    if (el == 'customer'):\n",
    "        customer_neighbours.append(tagged_words[i-1][0])\n",
    "        customer_neighbours_tags.append(tagged_words[i-1][1])\n",
    "        customer_neighbours.append(tagged_words[i+1][0])\n",
    "        customer_neighbours_tags.append(tagged_words[i+1][1])\n",
    "fd = nltk.FreqDist(customer_neighbours_tags)\n",
    "fd.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most action words are by \"not\", since the freq of Verbs are highest with \"not\". \"great\" and \"customer\" is used more with nouns, which means it is used for description."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most people think of sentiment as the emotion in a text - however, the definition can be broader than that: \"a view of or attitude toward a situation or event; an opinion.\"\n",
    "\n",
    "## Given the results from above - what is the sentiment for each word? How are they used and what does that imply about the writers/speakers/etc.?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets review sentiment of each word below:\n",
    "<br>\n",
    "NOT - This is a verb and frequency of this word in the text of twitter data of American airline are used about 364 times and words with which it is used is not with the word great. \n",
    "<br>\n",
    "GREAT - This a noun which is being used with great customer which means that the reviews of american airlines having the word great customer is about 1.6%  of the number of reviews on their website.\n",
    "<br>\n",
    "CUSTOMER - The reviews of american airlines where the users have mentioned the word customers are occuring about 101 times which is used with negative words like worst poor and no.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
